{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtP72KSo_hL0"
      },
      "source": [
        "# Part 1: Decision Trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "St6DNdekiQts"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import load_iris, fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, max_error, r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHtwH3PM_0ZO"
      },
      "source": [
        "### Task 1: Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpV1RQhO_XMV",
        "outputId": "727c13f0-e0b2-4e49-a540-f39820d73e8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Base model hyperparameters:  {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}\n",
            "Accuracy using base model on training data: 100.00 %\n",
            "Accuracy using base model on testing data: 100.00 %\n",
            "\n",
            "Best hyperparameters:  {'min_samples_split': 5, 'min_samples_leaf': 4, 'max_depth': 9, 'criterion': 'log_loss'}\n",
            "Accuracy using model with best hyperparameters on training data: 96.67 %\n",
            "Accuracy using base model on testing data: 100.00 %\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Load the Iris dataset.\n",
        "'''\n",
        "iris = load_iris()\n",
        "\n",
        "'''\n",
        "Split the data into training and testing sets.\n",
        "'''\n",
        "iris_X = iris.data\n",
        "iris_y = iris.target\n",
        "iris_X_train, iris_X_test, iris_y_train, iris_y_test = train_test_split(iris_X, iris_y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "'''\n",
        "Implement a DT classifier.\n",
        "'''\n",
        "clf = DecisionTreeClassifier(random_state = 42)\n",
        "clf.fit(iris_X_train, iris_y_train)\n",
        "\n",
        "'''\n",
        "Perform a Random Search to find the best hyperparameters for the DT classifier.\n",
        "Search for hyperparameters like max depth, min samples split, min samples leaf,\n",
        "and criterion. HInt: Use the RandomizedSearchCV function from scikit-learn.\n",
        "'''\n",
        "max_depth = [int(x) for x in np.linspace(2, 10, 9)]\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "criterion = [\"gini\", \"entropy\", \"log_loss\"]\n",
        "\n",
        "random_grid = {\n",
        "    \"max_depth\" : max_depth,\n",
        "    \"min_samples_split\" : min_samples_split,\n",
        "    \"min_samples_leaf\" : min_samples_leaf,\n",
        "    \"criterion\" : criterion\n",
        "}\n",
        "\n",
        "optimal_clf = RandomizedSearchCV(\n",
        "    estimator = clf,\n",
        "    param_distributions = random_grid,\n",
        "    n_iter = 50,\n",
        "    cv = 5,\n",
        "    random_state = 42\n",
        ")\n",
        "\n",
        "optimal_clf.fit(iris_X_train, iris_y_train)\n",
        "\n",
        "'''\n",
        "Print the best hyperparameters and the modelâ€™s accuracy with these\n",
        "hyperparameters.\n",
        "'''\n",
        "print(\"Base model hyperparameters: \", clf.get_params())\n",
        "print(\"Accuracy using base model on training data: %.2f\" % (accuracy_score(iris_y_train, clf.predict(iris_X_train)) * 100), \"%\")\n",
        "print(\"Accuracy using base model on testing data: %.2f\" % (accuracy_score(iris_y_test, clf.predict(iris_X_test)) * 100), \"%\")\n",
        "print()\n",
        "print(\"Best hyperparameters: \", optimal_clf.best_params_)\n",
        "print(\"Accuracy using model with best hyperparameters on training data: %.2f\" % (accuracy_score(iris_y_train, optimal_clf.predict(iris_X_train)) * 100), \"%\")\n",
        "print(\"Accuracy using base model on testing data: %.2f\" % (accuracy_score(iris_y_test, optimal_clf.predict(iris_X_test)) * 100), \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlFYOcq3_5bH"
      },
      "source": [
        "### Task 2: Error Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5fSwnBwAfLt",
        "outputId": "5c7115de-663a-43f1-b5f6-e7cc8e5a26e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy using base model on testing data:  100.0 %\n",
            "Accuracy using model with best hyperparameters on testing data:  100.0 %\n",
            "\n",
            "Using the base model on the training data, the following indices are misclassified: \n",
            "Using the base model on the testing data, the following indices are misclassified: \n",
            "\n",
            "Using the model with the best hyperparameters on the training data, the following indices are misclassified: 59, 62, 68, 116\n",
            "Using the model with the best hyperparameters on the testing data, the following indices are misclassified: \n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "After training the DT model with the best hyperparameters from Task 1, use this\n",
        "model to make predictions on the test data.\n",
        "'''\n",
        "print(\"Accuracy using base model on testing data: \", accuracy_score(iris_y_test, clf.predict(iris_X_test)) * 100, \"%\")\n",
        "print(\"Accuracy using model with best hyperparameters on testing data: \", accuracy_score(iris_y_test, optimal_clf.predict(iris_X_test)) * 100, \"%\")\n",
        "print()\n",
        "\n",
        "'''\n",
        "Identify and print the indices of misclassified instances (where the true class\n",
        "is not equal to the predicted class).\n",
        "'''\n",
        "def misclassified_indices(true_classes, predicted_classes, model, data):\n",
        "  indices = np.argwhere(true_classes != predicted_classes)\n",
        "  print(\"Using the %s on the %s, the following indices are misclassified: \" % (model, data), end = \"\")\n",
        "  if len(indices) > 0:\n",
        "    i = 0\n",
        "    while i < len(indices)-1:\n",
        "      print(indices[i][0], end = \", \")\n",
        "      i += 1\n",
        "    print(indices[i][0])\n",
        "  else:\n",
        "    print()\n",
        "\n",
        "misclassified_indices(iris_y_train, clf.predict(iris_X_train), \"base model\", \"training data\")\n",
        "misclassified_indices(iris_y_test, clf.predict(iris_X_test), \"base model\", \"testing data\")\n",
        "print()\n",
        "misclassified_indices(iris_y_train, optimal_clf.predict(iris_X_train), \"model with the best hyperparameters\", \"training data\")\n",
        "misclassified_indices(iris_y_test, optimal_clf.predict(iris_X_test), \"model with the best hyperparameters\", \"testing data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlRo42toAoYh"
      },
      "source": [
        "### Task 3: Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4_pONiLAzCj",
        "outputId": "7a91519d-65bf-4a12-daad-a596ea42eede"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Base Classifier Model Using Training Data\n",
            "\n",
            "positive (1) class:  setosa\n",
            "negative (0) classes:   versicolor virginica\n",
            "\t\t    predicted\n",
            "\t\t1\t\t0\n",
            "actual\t -------------------------------\n",
            "  1\t|    TP: 40 \t|    FN: 0 \t|\n",
            "\t|---------------|---------------|\n",
            "  0\t|    FP: 0 \t|    TN: 80 \t|\n",
            "\t -------------------------------\n",
            "\n",
            "\n",
            "positive (1) class:  versicolor\n",
            "negative (0) classes:  setosa  virginica\n",
            "\t\t    predicted\n",
            "\t\t1\t\t0\n",
            "actual\t -------------------------------\n",
            "  1\t|    TP: 41 \t|    FN: 0 \t|\n",
            "\t|---------------|---------------|\n",
            "  0\t|    FP: 0 \t|    TN: 79 \t|\n",
            "\t -------------------------------\n",
            "\n",
            "\n",
            "positive (1) class:  virginica\n",
            "negative (0) classes:  setosa versicolor \n",
            "\t\t    predicted\n",
            "\t\t1\t\t0\n",
            "actual\t -------------------------------\n",
            "  1\t|    TP: 39 \t|    FN: 0 \t|\n",
            "\t|---------------|---------------|\n",
            "  0\t|    FP: 0 \t|    TN: 81 \t|\n",
            "\t -------------------------------\n",
            "\n",
            "\n",
            "****************************************************************************\n",
            "\n",
            "Classifier Model With Best Hyperparameters Using Training Data\n",
            "\n",
            "positive (1) class:  setosa\n",
            "negative (0) classes:   versicolor virginica\n",
            "\t\t    predicted\n",
            "\t\t1\t\t0\n",
            "actual\t -------------------------------\n",
            "  1\t|    TP: 40 \t|    FN: 0 \t|\n",
            "\t|---------------|---------------|\n",
            "  0\t|    FP: 0 \t|    TN: 80 \t|\n",
            "\t -------------------------------\n",
            "\n",
            "\n",
            "positive (1) class:  versicolor\n",
            "negative (0) classes:  setosa  virginica\n",
            "\t\t    predicted\n",
            "\t\t1\t\t0\n",
            "actual\t -------------------------------\n",
            "  1\t|    TP: 39 \t|    FN: 2 \t|\n",
            "\t|---------------|---------------|\n",
            "  0\t|    FP: 2 \t|    TN: 77 \t|\n",
            "\t -------------------------------\n",
            "\n",
            "\n",
            "positive (1) class:  virginica\n",
            "negative (0) classes:  setosa versicolor \n",
            "\t\t    predicted\n",
            "\t\t1\t\t0\n",
            "actual\t -------------------------------\n",
            "  1\t|    TP: 37 \t|    FN: 2 \t|\n",
            "\t|---------------|---------------|\n",
            "  0\t|    FP: 2 \t|    TN: 79 \t|\n",
            "\t -------------------------------\n",
            "\n",
            "\n",
            "****************************************************************************\n",
            "\n",
            "Base Classifier Model Using Testing Data\n",
            "\n",
            "positive (1) class:  setosa\n",
            "negative (0) classes:   versicolor virginica\n",
            "\t\t    predicted\n",
            "\t\t1\t\t0\n",
            "actual\t -------------------------------\n",
            "  1\t|    TP: 10 \t|    FN: 0 \t|\n",
            "\t|---------------|---------------|\n",
            "  0\t|    FP: 0 \t|    TN: 20 \t|\n",
            "\t -------------------------------\n",
            "\n",
            "\n",
            "positive (1) class:  versicolor\n",
            "negative (0) classes:  setosa  virginica\n",
            "\t\t    predicted\n",
            "\t\t1\t\t0\n",
            "actual\t -------------------------------\n",
            "  1\t|    TP: 9 \t|    FN: 0 \t|\n",
            "\t|---------------|---------------|\n",
            "  0\t|    FP: 0 \t|    TN: 21 \t|\n",
            "\t -------------------------------\n",
            "\n",
            "\n",
            "positive (1) class:  virginica\n",
            "negative (0) classes:  setosa versicolor \n",
            "\t\t    predicted\n",
            "\t\t1\t\t0\n",
            "actual\t -------------------------------\n",
            "  1\t|    TP: 11 \t|    FN: 0 \t|\n",
            "\t|---------------|---------------|\n",
            "  0\t|    FP: 0 \t|    TN: 19 \t|\n",
            "\t -------------------------------\n",
            "\n",
            "\n",
            "****************************************************************************\n",
            "\n",
            "Classifier Model With Best Hyperparameters Using Testing Data\n",
            "\n",
            "positive (1) class:  setosa\n",
            "negative (0) classes:   versicolor virginica\n",
            "\t\t    predicted\n",
            "\t\t1\t\t0\n",
            "actual\t -------------------------------\n",
            "  1\t|    TP: 10 \t|    FN: 0 \t|\n",
            "\t|---------------|---------------|\n",
            "  0\t|    FP: 0 \t|    TN: 20 \t|\n",
            "\t -------------------------------\n",
            "\n",
            "\n",
            "positive (1) class:  versicolor\n",
            "negative (0) classes:  setosa  virginica\n",
            "\t\t    predicted\n",
            "\t\t1\t\t0\n",
            "actual\t -------------------------------\n",
            "  1\t|    TP: 9 \t|    FN: 0 \t|\n",
            "\t|---------------|---------------|\n",
            "  0\t|    FP: 0 \t|    TN: 21 \t|\n",
            "\t -------------------------------\n",
            "\n",
            "\n",
            "positive (1) class:  virginica\n",
            "negative (0) classes:  setosa versicolor \n",
            "\t\t    predicted\n",
            "\t\t1\t\t0\n",
            "actual\t -------------------------------\n",
            "  1\t|    TP: 11 \t|    FN: 0 \t|\n",
            "\t|---------------|---------------|\n",
            "  0\t|    FP: 0 \t|    TN: 19 \t|\n",
            "\t -------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Calculate the confusion matrix for the modelâ€™s predictions on the test data.\n",
        "'''\n",
        "# pregnant=P=1; not pregnant=N=0 (using pregnancy to think through T/F N/P)\n",
        "# TP: pregnancy test predicts pregnancy, woman is pregnant; predicted=1, actual=1\n",
        "# TN: pregnancy test predicts not pregnant, woman is not pregnant; predicted=0, actual=0\n",
        "# FP: pregnancy test predicts pregnant, woman is not pregnant; predicted=1, actual=0\n",
        "# FN: pregnancy test predicts not pregnant, woman is pregnant; predicted=0, actual=1\n",
        "\n",
        "def confusion_matrix_values(true_classes, predicted_classes, positive_class):\n",
        "  TP = 0\n",
        "  TN = 0\n",
        "  FP = 0\n",
        "  FN = 0\n",
        "  for i, value in enumerate(predicted_classes):\n",
        "    if value == positive_class:\n",
        "      if true_classes[i] == positive_class:\n",
        "        TP += 1\n",
        "      else:\n",
        "        FP += 1\n",
        "    else:\n",
        "      if true_classes[i] == positive_class:\n",
        "        FN += 1\n",
        "      else:\n",
        "        TN += 1\n",
        "  return [positive_class, TP, TN, FP, FN]\n",
        "\n",
        "def print_confusion_matrix(values, key):\n",
        "  positive_class = key[int(values[0])]\n",
        "  negative_classes = \" \".join(np.where(key != positive_class, key, \"\"))\n",
        "  print(\"positive (1) class: \", positive_class)\n",
        "  print(\"negative (0) classes: \", negative_classes)\n",
        "  print(\"\\t\\t    predicted\")\n",
        "  print(\"\\t\\t1\\t\\t0\")\n",
        "  print(\"actual\\t -------------------------------\")\n",
        "  print(\"  1\\t|    TP:\", values[1], \"\\t|    FN:\", values[4], \"\\t|\")\n",
        "  print(\"\\t|---------------|---------------|\")\n",
        "  print(\"  0\\t|    FP:\", values[3], \"\\t|    TN:\", values[2], \"\\t|\")\n",
        "  print(\"\\t -------------------------------\")\n",
        "  print()\n",
        "  print()\n",
        "\n",
        "'''\n",
        "Print the confusion matrix values (True Positives, True Negatives, False\n",
        "Positives, False Negatives).\n",
        "'''\n",
        "print(\"Base Classifier Model Using Training Data\\n\")\n",
        "for i in range(len(iris.target_names)):\n",
        "  print_confusion_matrix(confusion_matrix_values(iris_y_train, clf.predict(iris_X_train), i), iris.target_names)\n",
        "print(\"****************************************************************************\")\n",
        "print()\n",
        "\n",
        "print(\"Classifier Model With Best Hyperparameters Using Training Data\\n\")\n",
        "for i in range(len(iris.target_names)):\n",
        "  print_confusion_matrix(confusion_matrix_values(iris_y_train, optimal_clf.predict(iris_X_train), i), iris.target_names)\n",
        "print(\"****************************************************************************\")\n",
        "print()\n",
        "\n",
        "print(\"Base Classifier Model Using Testing Data\\n\")\n",
        "for i in range(len(iris.target_names)):\n",
        "  print_confusion_matrix(confusion_matrix_values(iris_y_test, clf.predict(iris_X_test), i), iris.target_names)\n",
        "print(\"****************************************************************************\")\n",
        "print()\n",
        "\n",
        "print(\"Classifier Model With Best Hyperparameters Using Testing Data\\n\")\n",
        "for i in range(len(iris.target_names)):\n",
        "  print_confusion_matrix(confusion_matrix_values(iris_y_test, optimal_clf.predict(iris_X_test), i), iris.target_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiAoKqN0A8Uz"
      },
      "source": [
        "### Task 4: Regression with DTs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GvZcGNcA_9W",
        "outputId": "57d73d12-2bc5-45d8-d880-9e082419f0f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error:  0.495235205629094\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Load a dataset suitable for regression (e.g., the Boston housing dataset from\n",
        "scikit-learn).\n",
        "'''\n",
        "# The Boston housing dataset has been phased out due to ethical concerns.\n",
        "# The following dataset is comparable and was recommended in sklearn literature\n",
        "# as an alternative.\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "'''\n",
        "Split the dataset into training and testing sets.\n",
        "'''\n",
        "housing_X = housing.data\n",
        "housing_y = housing.target\n",
        "housing_X_train, housing_X_test, housing_y_train, housing_y_test = train_test_split(housing_X, housing_y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "'''\n",
        "Implement a DT regression model.\n",
        "'''\n",
        "regressor = DecisionTreeRegressor(random_state = 42)\n",
        "\n",
        "'''\n",
        "Train the model on the training data.\n",
        "'''\n",
        "regressor.fit(housing_X_train, housing_y_train)\n",
        "\n",
        "'''\n",
        "Calculate and print the mean squared error (MSE) on the testing data to assess\n",
        "the modelâ€™s performance.\n",
        "'''\n",
        "print(\"Mean Squared Error: \", mean_squared_error(housing_y_test, regressor.predict(housing_X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am01g6QeBUFC"
      },
      "source": [
        "### Task 5: Metrics Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "pWXurzv4BYQz",
        "outputId": "18540106-c68d-437f-8333-d66f0785944a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nCompare the performance of the DT classifier from Task 1 and the DT regression\\nmodel from Task 4.\\n'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "Compare the performance of the DT classifier from Task 1 and the DT regression\n",
        "model from Task 4.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_S1I09U0QoH"
      },
      "source": [
        "It is difficult to directly compare the performance of the classifier and the regressor since they were used on 2 completely different sets of data. Furthermore, their performance was measured using two different metrics - accuracy for the classifier and mean squared error for the regressor. I can point out that, when used to predict the testing data, the classifier (both the base classifier and the classifier using the best hyperparameters*) was 100% accurate, where the regressor was not. In this way, perhaps the classifier performed \"better,\" but in reality, the classifier and the regressor are simply meant for different situations.\n",
        "\n",
        "*Something to note is that the classifier using the best hyperparameters actually performed worse on the training data than did the base classifier. Possibly, this is indicative of overfitting in the base classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzekbO4R0RVX",
        "outputId": "bdc7de2d-a347-4e6b-a1e6-8cfb9c4d6f5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifier Metrics\n",
            "\n",
            "Base classifier\n",
            "Accuracy:  1.0\n",
            "setosa\n",
            "Precision: 1.00; Recall: 1.00; F1-Score: 1.00\n",
            "versicolor\n",
            "Precision: 1.00; Recall: 1.00; F1-Score: 1.00\n",
            "virginica\n",
            "Precision: 1.00; Recall: 1.00; F1-Score: 1.00\n",
            "\n",
            "\n",
            "Classifier using best hyperparameters\n",
            "Accuracy:  1.0\n",
            "setosa\n",
            "Precision: 1.00; Recall: 1.00; F1-Score: 1.00\n",
            "versicolor\n",
            "Precision: 1.00; Recall: 1.00; F1-Score: 1.00\n",
            "virginica\n",
            "Precision: 1.00; Recall: 1.00; F1-Score: 1.00\n",
            "\n",
            "****************************************************************************\n",
            "\n",
            "Regressor Metrics\n",
            "\n",
            "MSE:  0.495235205629094\n",
            "Max Error:  4.100009999999999\n",
            "R-squared:  0.622075845135081\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Calculate and print relevant evaluation metrics for the classifier (e.g.,\n",
        "accuracy, precision, recall, F1-score) and the regression model (e.g., MSE).\n",
        "'''\n",
        "def clf_evaluation_metrics(values, key):\n",
        "  positive_class = key[int(values[0])]\n",
        "  precision = values[1] / (values[1] + values[3])\n",
        "  recall = values[1] / (values[1] + values[4])\n",
        "  f1 = 2 * precision * recall / (precision + recall)\n",
        "  print(positive_class)\n",
        "  print(\"Precision: %.2f; Recall: %.2f; F1-Score: %.2f\" % (precision, recall, f1))\n",
        "\n",
        "print(\"Classifier Metrics\")\n",
        "print()\n",
        "print(\"Base classifier\")\n",
        "print(\"Accuracy: \", accuracy_score(iris_y_test, clf.predict(iris_X_test)))\n",
        "\n",
        "for i in range(len(iris.target_names)):\n",
        "  clf_evaluation_metrics(confusion_matrix_values(iris_y_test, clf.predict(iris_X_test), i), iris.target_names)\n",
        "print()\n",
        "print()\n",
        "\n",
        "print(\"Classifier using best hyperparameters\")\n",
        "print(\"Accuracy: \", accuracy_score(iris_y_test, optimal_clf.predict(iris_X_test)))\n",
        "\n",
        "for i in range(len(iris.target_names)):\n",
        "  clf_evaluation_metrics(confusion_matrix_values(iris_y_test, optimal_clf.predict(iris_X_test), i), iris.target_names)\n",
        "print()\n",
        "print(\"****************************************************************************\")\n",
        "print()\n",
        "\n",
        "print(\"Regressor Metrics\")\n",
        "print()\n",
        "print(\"MSE: \", mean_squared_error(housing_y_test, regressor.predict(housing_X_test)))\n",
        "print(\"Max Error: \", max_error(housing_y_test, regressor.predict(housing_X_test)))\n",
        "print(\"R-squared: \", r2_score(housing_y_test, regressor.predict(housing_X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7GgjMsF7OPem",
        "outputId": "fbfbc5f3-37b5-4bd5-d472-5e4ba9556075"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nDiscuss the results, including which model performed better and why.\\n'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "Discuss the results, including which model performed better and why.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAPuEWryOUNw"
      },
      "source": [
        "Again, it is difficult to directly compare the models because they are used for different purposes, on different datasets, and are evaluated using different metrics. The classifiers have 100% accuracy when predicting the testing data, so they could be said to be better than the regressor. However, the data that is being predicted is simply different. The regressor is used to predict data that is continuous (the value of houses in California), which is more complicated and far harder to predict with absolutely no error. The classifier need only \"choose\" between 3 options (iris species).\n",
        "\n",
        "I will say that the regressor's R-squared value of about 0.62 is not very good and suggests that only about 62% of the variation in the housing values can be explained by the regressor model; the rest of the variation is due to error. However, there is still plenty of room to improve both the regressor model and the classifier model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCqvio-f_mGZ"
      },
      "source": [
        "# Part 2: Support Vector Machine (SVM) - Linear and w/ RBF Kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IPo4x5UZn52"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbCTMuWoBsNV"
      },
      "source": [
        "### Task 1: Linear Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9mMciG-Bvx7",
        "outputId": "b5d435c3-fdb3-4d6f-fcea-2aae899cef8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of LSVM: 100.00 %\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Load the Iris dataset.\n",
        "'''\n",
        "iris = load_iris()\n",
        "\n",
        "'''\n",
        "Split the data into training and testing sets.\n",
        "'''\n",
        "iris_X = iris.data\n",
        "iris_y = iris.target\n",
        "iris_X_train, iris_X_test, iris_y_train, iris_y_test = train_test_split(iris_X, iris_y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "'''\n",
        "Implement a Linear Support Vector Machine (SVM) classifier using scikit-learn.\n",
        "'''\n",
        "linear_clf = SVC(kernel = \"linear\", random_state = 42)\n",
        "\n",
        "'''\n",
        "Train the LSVM model on the training data.\n",
        "'''\n",
        "linear_clf.fit(iris_X_train, iris_y_train)\n",
        "\n",
        "'''\n",
        "Evaluate the LSVM modelâ€™s performance on the test data and report accuracy.\n",
        "'''\n",
        "print(\"Accuracy of LSVM: %.2f\" % (accuracy_score(iris_y_test, linear_clf.predict(iris_X_test)) *100), \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux0DsGPxB_BN"
      },
      "source": [
        "### Task 2: Support Vector Machine (SVM) with RBF Kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn0Eej0cCGH9",
        "outputId": "9033e657-abea-47b5-c1d9-03575d2d5e81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of RBF SVM: 100.00 %\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Load the Iris dataset.\n",
        "'''\n",
        "iris = load_iris()\n",
        "\n",
        "'''\n",
        "Split the data into training and testing sets.\n",
        "'''\n",
        "iris_X = iris.data\n",
        "iris_y = iris.target\n",
        "iris_X_train, iris_X_test, iris_y_train, iris_y_test = train_test_split(iris_X, iris_y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "'''\n",
        "Implement a Support Vector Machine (SVM) classifier with an RBF kernel using\n",
        "scikit-learn.\n",
        "'''\n",
        "rbf_clf = SVC(kernel = \"rbf\", random_state = 42)\n",
        "\n",
        "'''\n",
        "Train the SVM model with the RBF kernel on the training data.\n",
        "'''\n",
        "rbf_clf.fit(iris_X_train, iris_y_train)\n",
        "'''\n",
        "Evaluate the SVM modelâ€™s performance on the test data and report accuracy.\n",
        "'''\n",
        "print(\"Accuracy of RBF SVM: %.2f\" % (accuracy_score(iris_y_test, rbf_clf.predict(iris_X_test)) *100), \"%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWJq63ZrCZAv"
      },
      "source": [
        "### Task 3: Hyperparameter Tuning for SVM with RBF Kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuCfPFLHCeB_",
        "outputId": "3b7221c4-dccc-46e1-d70c-d411f32840c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters:  {'gamma': 1e-08, 'C': 10000000000.0}\n",
            "Accuracy of RBF SVM using best hyperparameters: 100.00 %\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Perform hyperparameter tuning for the SVM with an RBF kernel. Search for optimal\n",
        "values of hyperparameters such as C and Î³ using Random Search.\n",
        "'''\n",
        "C = np.logspace(-2, 10, 13)\n",
        "gamma = np.logspace(-9, 3, 13)\n",
        "\n",
        "random_grid = {\n",
        "    \"C\" : C,\n",
        "    \"gamma\" : gamma\n",
        "}\n",
        "\n",
        "optimal_rbf_clf = RandomizedSearchCV(\n",
        "    estimator = rbf_clf,\n",
        "    param_distributions = random_grid,\n",
        "    n_iter = 50,\n",
        "    cv = 5,\n",
        "    random_state = 42\n",
        ")\n",
        "\n",
        "optimal_rbf_clf.fit(iris_X_train, iris_y_train)\n",
        "\n",
        "'''\n",
        "Report the best hyperparameters for the SVM with the RBF kernel.\n",
        "'''\n",
        "print(\"Best hyperparameters: \", optimal_rbf_clf.best_params_)\n",
        "\n",
        "\n",
        "'''\n",
        "Train a new SVM model with the best hyperparameters and evaluate its performance\n",
        "on the test data.\n",
        "'''\n",
        "print(\"Accuracy of RBF SVM using best hyperparameters: %.2f\" % (accuracy_score(iris_y_test, optimal_rbf_clf.predict(iris_X_test)) * 100), \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8E15rezCtkN"
      },
      "source": [
        "### Task 4: Metrics Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B7lcFYwCzMs",
        "outputId": "f666f7d0-5021-408d-b5f5-e75ce55b92ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Data\n",
            "\n",
            "Linear SVM\n",
            "Accuracy:  0.975\n",
            "setosa\n",
            "Precision: 1.00; Recall: 1.00; F1-Score: 1.00\n",
            "versicolor\n",
            "Precision: 0.97; Recall: 0.95; F1-Score: 0.96\n",
            "virginica\n",
            "Precision: 0.95; Recall: 0.97; F1-Score: 0.96\n",
            "\n",
            "\n",
            "RBF SVM\n",
            "Accuracy:  0.975\n",
            "setosa\n",
            "Precision: 1.00; Recall: 1.00; F1-Score: 1.00\n",
            "versicolor\n",
            "Precision: 0.97; Recall: 0.95; F1-Score: 0.96\n",
            "virginica\n",
            "Precision: 0.95; Recall: 0.97; F1-Score: 0.96\n",
            "\n",
            "*******************************************************************\n",
            "\n",
            "Testing Data\n",
            "\n",
            "Linear SVM\n",
            "Accuracy:  1.0\n",
            "setosa\n",
            "Precision: 1.00; Recall: 1.00; F1-Score: 1.00\n",
            "versicolor\n",
            "Precision: 1.00; Recall: 1.00; F1-Score: 1.00\n",
            "virginica\n",
            "Precision: 1.00; Recall: 1.00; F1-Score: 1.00\n",
            "\n",
            "\n",
            "RBF SVM\n",
            "Accuracy:  1.0\n",
            "setosa\n",
            "Precision: 1.00; Recall: 1.00; F1-Score: 1.00\n",
            "versicolor\n",
            "Precision: 1.00; Recall: 1.00; F1-Score: 1.00\n",
            "virginica\n",
            "Precision: 1.00; Recall: 1.00; F1-Score: 1.00\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Calculate and compare relevant evaluation metrics (e.g., accuracy, precision,\n",
        "recall, F1-score) for the LSVM from Task 1 and the SVM with an RBF kernel from\n",
        "Task 2.\n",
        "'''\n",
        "print(\"Training Data\")\n",
        "print()\n",
        "\n",
        "print(\"Linear SVM\")\n",
        "print(\"Accuracy: \", accuracy_score(iris_y_train, linear_clf.predict(iris_X_train)))\n",
        "\n",
        "for i in range(len(iris.target_names)):\n",
        "  clf_evaluation_metrics(confusion_matrix_values(iris_y_train, linear_clf.predict(iris_X_train), i), iris.target_names)\n",
        "print()\n",
        "print()\n",
        "\n",
        "print(\"RBF SVM\")\n",
        "print(\"Accuracy: \", accuracy_score(iris_y_train, rbf_clf.predict(iris_X_train)))\n",
        "\n",
        "for i in range(len(iris.target_names)):\n",
        "  clf_evaluation_metrics(confusion_matrix_values(iris_y_train, rbf_clf.predict(iris_X_train), i), iris.target_names)\n",
        "print()\n",
        "print(\"*******************************************************************\")\n",
        "print()\n",
        "\n",
        "print(\"Testing Data\")\n",
        "print()\n",
        "\n",
        "print(\"Linear SVM\")\n",
        "print(\"Accuracy: \", accuracy_score(iris_y_test, linear_clf.predict(iris_X_test)))\n",
        "\n",
        "for i in range(len(iris.target_names)):\n",
        "  clf_evaluation_metrics(confusion_matrix_values(iris_y_test, linear_clf.predict(iris_X_test), i), iris.target_names)\n",
        "print()\n",
        "print()\n",
        "\n",
        "print(\"RBF SVM\")\n",
        "print(\"Accuracy: \", accuracy_score(iris_y_test, rbf_clf.predict(iris_X_test)))\n",
        "\n",
        "for i in range(len(iris.target_names)):\n",
        "  clf_evaluation_metrics(confusion_matrix_values(iris_y_test, rbf_clf.predict(iris_X_test), i), iris.target_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "KyoMDSuniuDa",
        "outputId": "34449df6-c380-47f8-b92c-1bcd488b8296"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nNot graded: Discuss the differences in performance and characteristics between\\nthese models.\\n'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "Not graded: Discuss the differences in performance and characteristics between\n",
        "these models.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WGm7wLRixtS"
      },
      "source": [
        "Based on their evaluation metrics, neither classifier performed better than the other on the training data or the testing data. The iris dataset is very simple, so nothing more complex than a linear svm is required. However, the more complex rbf svm can also classify the data.\n",
        "\n",
        "The small value of gamma (determined to be one of the best hyperparameters) suggests that the each of the training samples has a large influence on the model. The large value of C (again, determined to be one of the best hyperparameters) suggests that the svm classifier margin is small. The smaller margin means that each point is more accurately classified. Even though the large C makes the model more complex, because the dataset is so small, classification of the test data is not too cumbersome."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
