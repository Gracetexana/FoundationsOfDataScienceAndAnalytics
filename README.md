# Foundations of Data Science and Analytics - Taught by Professor Nidhi Rastogi at Rochester Institute of Technology

I enrolled in this course during my second semester at RIT from August 2023 to December 2023. We learned the inner workings of several machine learning models and implemented them. The primary programming language of this course was python and each of our assignments was completed using Google Colab.


## [Naive Bayes](LongToralesHW1.ipynb)

1. Load Iris dataset
2. Split data into test and train.
3. Calculate feature probabilities of training data on a Gaussian distribution.
4. Predict test data using training data probabilities.



## [Gradient Descent and Fine Tuning](LongToralesHW2.ipynb)

1. Generate synthetic data.
2. Implement gradient descent.
3. Fine tune gradient descent hyperparameters.
4. Display results.



## [Decision Trees and Support Vector Machines](LongToralesHW3.ipynb)

1. Decision tree for categorical data.
2. Decision tree for continuous data.
3. Linear support vector machine.
4. Support vector machine with RBF kernel.



## [Project](LongToralesProject.ipynb)

1. Create a problem statement for assigned <a href=https://scikit-learn.org/stable/datasets/real_world.html#newsgroups-dataset>dataset</a>.
2. Explain the data.
3. Exploratory data analysis.
4. Data preprocessing.
5. Data visualization.
6. Feature engineering.
7. Feature reduction.
8. Train models.
    - 4 multinomial logistic regression models optimized with gradient descent and having different values of alpha and using different regularization techniques
    - an RBF support vector machine using a one-versus-rest decision function (good for large datasets like mine)
    - a decision tree
    - a decision tree with tuned hyperparameters
    - a random forest
